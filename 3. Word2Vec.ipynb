{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "Meaning of word is the representation or idea conveyed. Word embeddings are numerical representations of the words to make computers understand natural language. The idea is to have similar words or words used in similar context to be close to each other in higher dimension space.\n",
    "\n",
    "But before we look at using word vectors, let us look at classical NLP approach, Wordnet.\n",
    "\n",
    "##### Wordnet\n",
    "\n",
    "- Wordnet is a lexical database encoding parts of speech and tags relationsships between words including nouns, adjectives, verbs and adverbs. \n",
    "- English Wordnet hosts over 150000 words and over 100000 synonym groups(synsets)\n",
    "- Synset is a set of synonyms\n",
    "- Each Synset has a definition which tells what the synset repesents\n",
    "- Each Synonym in a Synset is called a Lemma.\n",
    "- Synsets form a graph and are associated with another synset with a specific type of relationship\n",
    "- Following are the relationship types\n",
    "    - Hypernym of a synset carry a general, high level meaning of a considered synset. For e.g. Vehicle is a hypernym of synset car. It forms `is-a` relation\n",
    "    - Hyponym of a synset carry a more specific meaning of a synset. Toyota Car is a Hyponym of a car. It forms `is-a` relation\n",
    "    - Holonym are synsets that make up the whole entity of the considered synset. If is a `made-of` relation. For example, Tyre has a holonym cars.\n",
    "    - Meronym are opposite of Holonym, they form a `is-made-of` relation.\n",
    "    \n",
    "Let us look at wordnet in action from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/amolnayak/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset definitions for word car are\n",
      "\n",
      " a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "\n",
      "- a wheeled vehicle adapted to the rails of railroad\n",
      "\n",
      "- the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "\n",
      "- where passengers ride up and down\n",
      "\n",
      "- a conveyance for passengers or freight on a cable railway\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "word = 'car'\n",
    "car_syns = wn.synsets(word)\n",
    "\n",
    "synset_defs = [car_syn.definition() for car_syn in car_syns]\n",
    "print('Synset definitions for word', word, 'are\\n\\n','\\n\\n- '.join(synset_defs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get the hypernym and holonym of first synset of the cars we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernym of synset containing car are,\n",
      "\t motor_vehicle\n",
      "\t automotive_vehicle\n",
      "\n",
      "Hyponyms of synset containing car are,\n",
      "\t ambulance\n",
      "\t beach_wagon\n",
      "\t station_wagon\n",
      "\t wagon\n",
      "\t estate_car\n",
      "\t beach_waggon\n",
      "\t station_waggon\n",
      "\t waggon\n",
      "\t bus\n",
      "\t jalopy\n",
      "\t heap\n",
      "\t cab\n",
      "\t hack\n",
      "\t taxi\n",
      "\t taxicab\n",
      "\t compact\n",
      "\t compact_car\n",
      "\t convertible\n",
      "\t coupe\n",
      "\t cruiser\n",
      "\t police_cruiser\n",
      "\t patrol_car\n",
      "\t police_car\n",
      "\t prowl_car\n",
      "\t squad_car\n",
      "\t electric\n",
      "\t electric_automobile\n",
      "\t electric_car\n",
      "\t gas_guzzler\n",
      "\t hardtop\n",
      "\t hatchback\n",
      "\t horseless_carriage\n",
      "\t hot_rod\n",
      "\t hot-rod\n",
      "\t jeep\n",
      "\t landrover\n",
      "\t limousine\n",
      "\t limo\n",
      "\t loaner\n",
      "\t minicar\n",
      "\t minivan\n",
      "\t Model_T\n",
      "\t pace_car\n",
      "\t racer\n",
      "\t race_car\n",
      "\t racing_car\n",
      "\t roadster\n",
      "\t runabout\n",
      "\t two-seater\n",
      "\t sedan\n",
      "\t saloon\n",
      "\t sport_utility\n",
      "\t sport_utility_vehicle\n",
      "\t S.U.V.\n",
      "\t SUV\n",
      "\t sports_car\n",
      "\t sport_car\n",
      "\t Stanley_Steamer\n",
      "\t stock_car\n",
      "\t subcompact\n",
      "\t subcompact_car\n",
      "\t touring_car\n",
      "\t phaeton\n",
      "\t tourer\n",
      "\t used-car\n",
      "\t secondhand_car\n"
     ]
    }
   ],
   "source": [
    "car_syn = car_syns[0]\n",
    "\n",
    "hypernyms = car_syn.hypernyms()\n",
    "hypernym_list = '\\n\\t '.join(['\\n\\t '.join(h.lemma_names()) for h in hypernyms])\n",
    "print('Hypernym of synset containing car are,\\n\\t', hypernym_list)\n",
    "\n",
    "hyponyms = car_syn.hyponyms()\n",
    "hyponyms_list = '\\n\\t '.join(['\\n\\t '.join(h.lemma_names()) for h in hyponyms])\n",
    "print('\\nHyponyms of synset containing car are,\\n\\t', hyponyms_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, hypernyms are more general than the word `car` and the hyponyms are specyfic types of cars (most of them).\n",
    "\n",
    "Let us look at Holonyms and Meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Holonyms found\n",
      "Meronyms are\n",
      "\t accelerator\n",
      "\t accelerator_pedal\n",
      "\t gas_pedal\n",
      "\t gas\n",
      "\t throttle\n",
      "\t gun\n",
      "\t air_bag\n",
      "\t auto_accessory\n",
      "\t automobile_engine\n",
      "\t automobile_horn\n",
      "\t car_horn\n",
      "\t motor_horn\n",
      "\t horn\n",
      "\t hooter\n",
      "\t buffer\n",
      "\t fender\n",
      "\t bumper\n",
      "\t car_door\n",
      "\t car_mirror\n",
      "\t car_seat\n",
      "\t car_window\n",
      "\t fender\n",
      "\t wing\n",
      "\t first_gear\n",
      "\t first\n",
      "\t low_gear\n",
      "\t low\n",
      "\t floorboard\n",
      "\t gasoline_engine\n",
      "\t petrol_engine\n",
      "\t glove_compartment\n",
      "\t grille\n",
      "\t radiator_grille\n",
      "\t high_gear\n",
      "\t high\n",
      "\t hood\n",
      "\t bonnet\n",
      "\t cowl\n",
      "\t cowling\n",
      "\t luggage_compartment\n",
      "\t automobile_trunk\n",
      "\t trunk\n",
      "\t rear_window\n",
      "\t reverse\n",
      "\t reverse_gear\n",
      "\t roof\n",
      "\t running_board\n",
      "\t stabilizer_bar\n",
      "\t anti-sway_bar\n",
      "\t sunroof\n",
      "\t sunshine-roof\n",
      "\t tail_fin\n",
      "\t tailfin\n",
      "\t fin\n",
      "\t third_gear\n",
      "\t third\n",
      "\t window\n"
     ]
    }
   ],
   "source": [
    "holonyms = car_syn.part_holonyms()\n",
    "holonyms = '\\n\\t '.join(['\\n\\t '.join(h.lemma_names()) for h in holonyms])\n",
    "if len(holonyms):\n",
    "    print('Holonyms are\\n\\t', holonyms)\n",
    "else:\n",
    "    print('No Holonyms found')\n",
    "\n",
    "meronyms = '\\n\\t '.join(['\\n\\t '.join(m.lemma_names()) for m in car_syn.part_meronyms()])\n",
    "if len(meronyms):\n",
    "    print('Meronyms are\\n\\t', meronyms)\n",
    "else:\n",
    "    print('No Meronyms found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, there are no holonyms of car but a car is composed of a lot of parts and thus we have found a lot of meronyms. \n",
    "\n",
    "If we choose a word from the above meronyms and find its holonyms, we should find car in it as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holonyms of sunroof are\n",
      "\t car\n",
      "\t auto\n",
      "\t automobile\n",
      "\t machine\n",
      "\t motorcar\n",
      "No meronyms for sunroof found\n"
     ]
    }
   ],
   "source": [
    "car_part = 'sunroof'\n",
    "first_synset = wn.synsets(car_part)[0]\n",
    "\n",
    "carpart_holonyms = '\\n\\t '.join(['\\n\\t '.join(h.lemma_names()) for h in first_synset.part_holonyms()])\n",
    "print('Holonyms of', car_part, 'are\\n\\t', carpart_holonyms)\n",
    "\n",
    "carpart_meronyms = '\\n\\t '.join(['\\n\\t '.join(h.lemma_names()) for h in first_synset.part_meronyms()])\n",
    "if len(carpart_meronyms):\n",
    "    print('Meronyms of', car_part, 'are\\n\\t', carpart_meronyms)\n",
    "else:\n",
    "    print('No meronyms for', car_part, 'found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now find similarities between the synsets. (TODO, get more info on similarity metrics). We will use Wu-Palmer similarity to find similarity between all pairs of ``car_syns``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmas in all the synsets are\n",
      "\t car, auto, automobile, machine, motorcar\n",
      "\t car, railcar, railway_car, railroad_car\n",
      "\t car, gondola\n",
      "\t car, elevator_car\n",
      "\t cable_car, car\n",
      "\n",
      "Wu-Palmer similarity matrix constructed is\n",
      " [[ 1.          0.72727273  0.47619048  0.47619048  0.47619048]\n",
      " [ 0.72727273  1.          0.52631579  0.52631579  0.52631579]\n",
      " [ 0.47619048  0.52631579  1.          0.9         0.9       ]\n",
      " [ 0.47619048  0.52631579  0.9         1.          0.9       ]\n",
      " [ 0.47619048  0.52631579  0.9         0.9         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "car_lemmas = '\\n\\t '.join([', '.join(s.lemma_names()) for s in car_syns])\n",
    "print('\\nLemmas in all the synsets are\\n\\t', car_lemmas)\n",
    "sim_mat = np.matrix([[wn.wup_similarity(syn1, syn2) for syn1 in car_syns] for syn2 in car_syns])\n",
    "print('\\nWu-Palmer similarity matrix constructed is\\n', sim_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File wikipedia2text-extracted.txt.bz2 already downloaded, using local copy\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def maybe_download(url, filename):\n",
    "    if os.path.exists(filename):\n",
    "        print('File %s already downloaded, using local copy'%filename)\n",
    "    else:\n",
    "        #Not handling exceptions and missing file errors\n",
    "        print('Downloading file %s from %s'%(filename, url))\n",
    "        local_filename, headers = urlretrieve(url + '/' + filename)\n",
    "        shutil.move(local_filename, filename)\n",
    "    \n",
    "maybe_download('http://www.evanjones.ca/software','wikipedia2text-extracted.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
