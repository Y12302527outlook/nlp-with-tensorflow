{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Introduction\n",
    "\n",
    "Implementation of RNNs for sentence generation using Keras. The reference taken is [this](https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/) website. The dataset use is Andrej Karpathy's [page](https://cs.stanford.edu/people/karpathy/char-rnn/)\n",
    "\n",
    "First we will download the text if required and load the data as characters in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Shakespeare/shakespeare_input.txt exists, not downloading\n",
      "Number of unique characters are 67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def maybe_download(target_url, local_dir, local_file):\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.mkdir(local_dir)\n",
    "        \n",
    "    complete_path = os.path.join(local_dir, local_file)\n",
    "    if os.path.exists(complete_path):\n",
    "        print('File %s exists, not downloading'%complete_path)\n",
    "    else:\n",
    "        print('Downloading %s'%target_url)\n",
    "        urlretrieve(target_url, complete_path)\n",
    "        print('File downloaded')\n",
    "    return complete_path\n",
    "\n",
    "url = 'https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt'\n",
    "local_file = maybe_download(url, 'Shakespeare', 'shakespeare_input.txt')\n",
    "\n",
    "with open(local_file, 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "chars = list(set(data))\n",
    "print('Number of unique characters are', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lookup and reverse lookup for vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {c:ix for ix, c in enumerate(chars)}\n",
    "ix_to_char = {ix:c for ix, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some parameters for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_length = 50 #Number of previous characters (timesteps) to train on\n",
    "\n",
    "vocab_size = len(chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define input and output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
