{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "TODO: Explain a bit of sentence generation\n",
    "\n",
    "#### What are RNNs\n",
    "\n",
    "Feed forward networks with input $x_t = \\{x_1, x_2 ... x_n\\}$ and output $y_t = \\{y_1, y_2 ... y_n\\}$ lets us predict y based on x. If x is a time series then all events from $x_1 .. x_{t-1}$ led to $x_t$ and we cannot model this behavior using feed forward network. We are looking to model the function\n",
    "\n",
    "$\n",
    "h_t = g_1(x_t, h_{t-1};\\theta)\\:and\\: y_t = g_2(h_t;\\gamma)\n",
    "$\n",
    "\n",
    "With feed forard network we cannot model this recursive network and thus we need RNNs\n",
    "\n",
    "#### Basic structure of an RNN\n",
    "\n",
    "One cell of RNN has an input `x` and generates output `y`. The intemediate state `h` is generated using `x` and using the intermediate state of the previous cell. The output `y` for the current cell is generated using `h` for current state.\n",
    "\n",
    "Assuming the input dimension is `d`, dimension of the hidden state `h` is `s` and number of output class are `c`. We therefore have 3 sets of weights\n",
    "\n",
    "- `w_1`: Which has has dimension $s \\times d$ and forms the set of weights between the input and hidden state\n",
    "- `w_2`: Which has dimension $s \\times s$ and forms the set of weights between the previous hidden state and current hidden state\n",
    "- `w_3`: Which has dimension $c \\times s$ and forms the weight matrix between the current hidden state and the current output\n",
    "\n",
    "\n",
    "Using these weights, we have\n",
    "\n",
    "$h_t = g_1(w_1\\cdot x_t + w_2\\cdot h_{t-1}) \\:and\\: y_t = g_2(w_3\\cdot h_t)$\n",
    "\n",
    "where $g_1$ and $g_2$ are some activation functions.\n",
    "\n",
    "\n",
    "#### Backpropagation in RNN\n",
    "\n",
    "Normal backpropagation in RNN as in a feedforward network doesnt work. This especially fails when we want to calculate the partial derivative of loss `L` by $w_2$\n",
    "\n",
    "Suppose the true label is `l`, then the derivative \n",
    "\n",
    "$\\frac{\\partial{L}}{\\partial{w_2}} = \\frac{\\partial{L}}{\\partial{y}} \\frac{\\partial{y}}{\\partial{h}} \\frac{\\partial{h}}{\\partial{w_2}}$\n",
    "\n",
    "The term $\\frac{\\partial{h}}{\\partial{w_2}}$ is tricky as $\\frac{\\partial{h}}{\\partial{w_2}} = \\frac{\\partial{(w_1\\cdot x + w_2\\cdot h)}}{\\partial{w_2}}$ and as we can see its recursive\n",
    "\n",
    "The solution is then to truncate derivative to some T steps back in time and not all the way to beginning.\n",
    "\n",
    "#### Implementing sentence generation in Tensorflow using RNN\n",
    "\n",
    "First we will download the corpus from [https://www.cs.cmu.edu/~spok/grimmtmp/](https://www.cs.cmu.edu/~spok/grimmtmp/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/001.txt to fairytales/001.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/002.txt to fairytales/002.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/003.txt to fairytales/003.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/004.txt to fairytales/004.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/005.txt to fairytales/005.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/006.txt to fairytales/006.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/007.txt to fairytales/007.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/008.txt to fairytales/008.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/009.txt to fairytales/009.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/010.txt to fairytales/010.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/011.txt to fairytales/011.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/012.txt to fairytales/012.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/013.txt to fairytales/013.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/014.txt to fairytales/014.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/015.txt to fairytales/015.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/016.txt to fairytales/016.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/017.txt to fairytales/017.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/018.txt to fairytales/018.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/019.txt to fairytales/019.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/020.txt to fairytales/020.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/021.txt to fairytales/021.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/022.txt to fairytales/022.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/023.txt to fairytales/023.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/024.txt to fairytales/024.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/025.txt to fairytales/025.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/026.txt to fairytales/026.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/027.txt to fairytales/027.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/028.txt to fairytales/028.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/029.txt to fairytales/029.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/030.txt to fairytales/030.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/031.txt to fairytales/031.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/032.txt to fairytales/032.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/033.txt to fairytales/033.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/034.txt to fairytales/034.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/035.txt to fairytales/035.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/036.txt to fairytales/036.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/037.txt to fairytales/037.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/038.txt to fairytales/038.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/039.txt to fairytales/039.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/040.txt to fairytales/040.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/041.txt to fairytales/041.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/042.txt to fairytales/042.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/043.txt to fairytales/043.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/044.txt to fairytales/044.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/045.txt to fairytales/045.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/046.txt to fairytales/046.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/047.txt to fairytales/047.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/048.txt to fairytales/048.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/049.txt to fairytales/049.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/050.txt to fairytales/050.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/051.txt to fairytales/051.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/052.txt to fairytales/052.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/053.txt to fairytales/053.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/054.txt to fairytales/054.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/055.txt to fairytales/055.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/056.txt to fairytales/056.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/057.txt to fairytales/057.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/058.txt to fairytales/058.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/059.txt to fairytales/059.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/060.txt to fairytales/060.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/061.txt to fairytales/061.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/062.txt to fairytales/062.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/063.txt to fairytales/063.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/064.txt to fairytales/064.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/065.txt to fairytales/065.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/066.txt to fairytales/066.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/067.txt to fairytales/067.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/068.txt to fairytales/068.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/069.txt to fairytales/069.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/070.txt to fairytales/070.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/071.txt to fairytales/071.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/072.txt to fairytales/072.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/073.txt to fairytales/073.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/074.txt to fairytales/074.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/075.txt to fairytales/075.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/076.txt to fairytales/076.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/077.txt to fairytales/077.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/078.txt to fairytales/078.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/079.txt to fairytales/079.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/080.txt to fairytales/080.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/081.txt to fairytales/081.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/082.txt to fairytales/082.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/083.txt to fairytales/083.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/084.txt to fairytales/084.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/085.txt to fairytales/085.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/086.txt to fairytales/086.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/087.txt to fairytales/087.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/088.txt to fairytales/088.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/089.txt to fairytales/089.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/090.txt to fairytales/090.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/091.txt to fairytales/091.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/092.txt to fairytales/092.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/093.txt to fairytales/093.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/094.txt to fairytales/094.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/095.txt to fairytales/095.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/096.txt to fairytales/096.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/097.txt to fairytales/097.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/098.txt to fairytales/098.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/099.txt to fairytales/099.txt\n",
      "Downloading from https://www.cs.cmu.edu/~spok/grimmtmp/100.txt to fairytales/100.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def maybe_download(target_url, target_dir, target_file):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "     \n",
    "    target_file = os.path.join(target_dir, target_file)\n",
    "    if os.path.exists(target_file):\n",
    "        print('File', target_file, 'exists, skipping download')\n",
    "    else:\n",
    "        print('Downloading from', target_url, 'to', target_file)\n",
    "        urlretrieve(target_url, target_file)\n",
    "        \n",
    "        \n",
    "target_dir = 'fairytales'\n",
    "base_url = 'https://www.cs.cmu.edu/~spok/grimmtmp/'\n",
    "\n",
    "for i in range(1, 101):\n",
    "    file_name = format(i, '03d') + '.txt'\n",
    "    maybe_download(base_url +  file_name, target_dir, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will be reading all files in the directory and convert them to list of strings, which then we will split into bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 bigrams from first 10 files are\n",
      "\n",
      "File  1 , bigrams[0:10] =  ['in', ' o', 'ld', 'en', ' t', 'im', 'es', ' w', 'he', 'n ']\n",
      "File  2 , bigrams[0:10] =  ['ha', 'rd', ' b', 'y ', 'a ', 'gr', 'ea', 't ', 'fo', 're']\n",
      "File  3 , bigrams[0:10] =  ['a ', 'ce', 'rt', 'ai', 'n ', 'fa', 'th', 'er', ' h', 'ad']\n",
      "File  4 , bigrams[0:10] =  ['th', 'er', 'e ', 'wa', 's ', 'on', 'ce', ' u', 'po', 'n ']\n",
      "File  5 , bigrams[0:10] =  ['th', 'er', 'e ', 'wa', 's ', 'on', 'ce', ' u', 'po', 'n ']\n",
      "File  6 , bigrams[0:10] =  ['th', 'er', 'e ', 'wa', 's ', 'on', 'ce', ' a', ' p', 'ea']\n",
      "File  7 , bigrams[0:10] =  ['th', 'er', 'e ', 'we', 're', ' o', 'nc', 'e ', 'up', 'on']\n",
      "File  8 , bigrams[0:10] =  ['li', 'tt', 'le', ' b', 'ro', 'th', 'er', ' t', 'oo', 'k ']\n",
      "File  9 , bigrams[0:10] =  ['th', 'er', 'e ', 'we', 're', ' o', 'nc', 'e ', 'a ', 'ma']\n",
      "File  10 , bigrams[0:10] =  ['th', 'er', 'e ', 'wa', 's ', 'on', 'ce', ' a', ' m', 'an']\n"
     ]
    }
   ],
   "source": [
    "def read_as_bigrams(file_name):\n",
    "    with open(file_name) as f:\n",
    "        content = f.read().lower()\n",
    "        \n",
    "    return [content[i:i + 2] for i in range(0, len(content) - 2, 2)]\n",
    "    \n",
    "bigrams = [read_as_bigrams(os.path.join(target_dir, f)) for f in os.listdir(target_dir)]\n",
    "\n",
    "print('first 10 bigrams from first 10 files are\\n')\n",
    "for i in range(10):\n",
    "    print('File ', (i + 1), ', bigrams[0:10] = ', bigrams[i][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All bigrams make up 449177 words\n",
      "Vocabulary is of size 544\n",
      "5 most common words are [('e ', 15229), ('he', 15164), (' t', 13443), ('th', 13076), ('d ', 10687)]\n",
      "5 least common words are [('nm', 1), ('m?', 1), ('\\t\"', 1), ('\\tw', 1), ('tz', 1)]\n",
      "Sample data 0 is [15, 28, 86, 23, 3, 95, 74, 11, 2, 16]\n",
      "Sample data 1 is [22, 156, 25, 37, 82, 185, 43, 9, 90, 19]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def build_dataset(documents, threshold = 10):\n",
    "    # Input\n",
    "    # documents: List of list of bigrams for each document\n",
    "    # threshold: The threshold which will classify rare words as UNK\n",
    "    #\n",
    "    # returns \n",
    "    # \n",
    "    # dictionary: Mapping between word and the numeric value for it\n",
    "    # reverse_dictionary: Mapping numeric value and the corresponding word\n",
    "    # count: tuples of word and the count\n",
    "    # data: list for each document where the corresponding word\n",
    "    \n",
    "    all_bigrams = []\n",
    "    for d in documents:\n",
    "        all_bigrams.extend(d)\n",
    "        \n",
    "    print('All bigrams make up', len(all_bigrams), 'words')\n",
    "    counts = collections.Counter(all_bigrams).most_common()\n",
    "    #\n",
    "    dictionary = {word : (i + 1) for i, (word, count) in enumerate(counts) if count > threshold}\n",
    "    dictionary['UNK'] = 0\n",
    "    \n",
    "    reverse_dictionary = {dictionary[k] : k for k in dictionary}\n",
    "    \n",
    "    print('Vocabulary is of size', len(reverse_dictionary))\n",
    "    \n",
    "    data = [[dictionary[b] if b in dictionary else dictionary['UNK'] for b in doc] for doc in documents]\n",
    "    \n",
    "    return dictionary, reverse_dictionary, counts, data\n",
    "    \n",
    "dictionary, reverse_dictionary, counts, data = build_dataset(bigrams)\n",
    "print('5 most common words are', counts[0:5])\n",
    "print('5 least common words are', counts[-5:])\n",
    "print('Sample data 0 is', data[0][0:10])\n",
    "print('Sample data 1 is', data[1][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e ',\n",
       " 'li',\n",
       " 've',\n",
       " 'd ',\n",
       " 'a ',\n",
       " 'ki',\n",
       " 'ng',\n",
       " '\\nw',\n",
       " 'ho',\n",
       " 'se',\n",
       " ' d',\n",
       " 'au',\n",
       " 'gh',\n",
       " 'te',\n",
       " 'rs',\n",
       " ' w',\n",
       " 'er',\n",
       " 'e ',\n",
       " 'al',\n",
       " 'l ',\n",
       " 'be',\n",
       " 'au',\n",
       " 'ti',\n",
       " 'fu',\n",
       " 'l,']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reverse_dictionary[i] for i in data[0][25:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text is ['e ', 'li', 've', 'd ', 'a ', 'ki', 'ng', '\\nw', 'ho', 'se', ' d', 'au', 'gh', 'te', 'rs', ' w', 'er', 'e ', 'al', 'l ', 'be', 'au', 'ti', 'fu', 'l,']\n",
      "Batch in Iteration 0\n",
      "Input is  ['e ', 'ki', ' d', ' w', 'be']\n",
      "Label is  ['li', 'ng', 'au', 'er', 'au']\n",
      "Batch in Iteration 1\n",
      "Input is  ['li', 'ng', 'au', 'er', 'au']\n",
      "Label is  ['ve', '\\nw', 'gh', 'e ', 'ti']\n",
      "Batch in Iteration 2\n",
      "Input is  ['ve', '\\nw', 'gh', 'e ', 'ti']\n",
      "Label is  ['d ', 'ho', 'te', 'al', 'fu']\n",
      "Batch in Iteration 3\n",
      "Input is  ['d ', 'ho', 'te', 'al', 'fu']\n",
      "Label is  ['a ', 'se', 'rs', 'l ', 'l,']\n",
      "Batch in Iteration 4\n",
      "Input is  ['a ', 'se', 'rs', 'l ', 'be']\n",
      "Label is  ['ki', ' d', ' w', 'be', 'au']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BatchGenerator(object):\n",
    "    \n",
    "    def __init__(self, text, vocab_size, batch_size, num_unroll):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.text = text\n",
    "        self._text_size = len(text)\n",
    "        self.split_size = self._text_size // batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_unroll = num_unroll\n",
    "        self._cursor = [i * self.split_size for i in range(batch_size)]\n",
    "    \n",
    "    \n",
    "    def next_batch(self):\n",
    "        #\n",
    "        #\n",
    "        batch_data = np.zeros(shape = [self.batch_size, self.vocab_size], dtype = np.float32)\n",
    "        batch_labels = np.zeros(shape = [self.batch_size, self.vocab_size], dtype = np.float32)\n",
    "        for b in range(self.batch_size):\n",
    "            \n",
    "            if self._cursor[b]+1>=self._text_size:\n",
    "                self._cursor[b] = b * self.split_size\n",
    "            \n",
    "            batch_cursor = self._cursor[b]\n",
    "            batch_data[b, self.text[batch_cursor]] = 1\n",
    "            batch_labels[b, self.text[batch_cursor + 1]] = 1\n",
    "            self._cursor[b] += 1\n",
    "            \n",
    "        return  batch_data, batch_labels\n",
    "    \n",
    "    \n",
    "    def unroll_batches(self):\n",
    "        #\n",
    "        #\n",
    "        unrolled_batches, unrolled_labels = [], []\n",
    "        for _ in range(self.num_unroll):\n",
    "            batch, labels = self.next_batch()\n",
    "            unrolled_batches.append(batch)\n",
    "            unrolled_labels.append(labels)\n",
    "            \n",
    "        return unrolled_batches, unrolled_labels\n",
    "        \n",
    "    def reset(self):        \n",
    "        self._cursor = [i * self.splits for i in range(self.batch_size)]\n",
    "        \n",
    "vocab_size = len(dictionary)\n",
    "batch_generator = BatchGenerator(data[0][25:50], vocab_size, 5, 5)\n",
    "print('Input text is', [reverse_dictionary[i] for i in data[0][25:50]])\n",
    "\n",
    "unrolled_batches, unrolled_labels = batch_generator.unroll_batches()\n",
    "    \n",
    "for i, (batch_data, batch_labels)  in enumerate(zip(unrolled_batches, unrolled_labels)):\n",
    "    print('Batch in Iteration', i)\n",
    "    print('Input is ',[reverse_dictionary[np.argmax(b)] for b in batch_data])\n",
    "    print('Label is ',[reverse_dictionary[np.argmax(b)] for b in batch_labels])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of timesteps to lookback in time\n",
    "num_unroll = 50\n",
    "\n",
    "#Size of hidden dimension\n",
    "state_size = 64\n",
    "\n",
    "#Training batch size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
